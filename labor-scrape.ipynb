{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85a46969",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from urllib.request import urlopen, Request\n",
    "from urllib.parse import urlencode\n",
    "# from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "# from selenium.webdriver.common.by import By\n",
    "# from selenium.webdriver.chrome.service import Service\n",
    "# from selenium.webdriver.support.select import Select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a85a754",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseURL='https://dol.ny.gov/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d67f8e6c",
   "metadata": {},
   "source": [
    "## CIVILIAN LABOR DATA: \n",
    "###### LABOR FORCE, EMPLOYED, EMP by POP percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ce366b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "originUrl='https://dol.ny.gov/labor-statistics-new-york-city-region'\n",
    "laborURL='statistics-new-york-city-labor-force-data'\n",
    "# download excel file from the link in url\n",
    "r= requests.get(baseURL+laborURL, allow_redirects=True)\n",
    "open('raw_data/jobs_data.xlsx', 'wb').write(r.content)\n",
    "\n",
    "# read the file\n",
    "rate_df=pd.read_excel('raw_data/jobs_data.xlsx', skiprows=2)\n",
    "\n",
    "# remove columns with no dates\n",
    "rate_df=rate_df.dropna(subset=['YEAR']).reset_index(drop=True)\n",
    "rate_df=rate_df[['YEAR', 'Labor Force', 'Employment', 'Emp/Pop', 'Unemp Rate']].replace(\",\", regex=True)\n",
    "rate_df[['Labor Force', 'Employment', 'Emp/Pop', 'Unemp Rate']]=rate_df[[\n",
    "    'Labor Force', 'Employment', 'Emp/Pop', 'Unemp Rate']].apply(pd.to_numeric)\n",
    "\n",
    "# pandemic_period=df[df.YEAR > '2000-01-01'].reset_index(drop=True)\n",
    "rate_df['month']=pd.to_datetime(rate_df['YEAR']).dt.strftime(\"%Y-%m\")\n",
    "rate_df[['month', \"Labor Force\"]].to_json('data/labor.json', orient='records')\n",
    "rate_df[['month', \"Employment\"]].to_json('data/employment.json', orient='records')\n",
    "rate_df[['month', 'Emp/Pop']].to_json('data/empPop.json', orient='records')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f696f2fe",
   "metadata": {},
   "source": [
    "## Unemployment rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7cad1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#script to scrape new unemployment rate for us and merge it with old data and nyc data\n",
    "national_unemp_url = \"https://data.bls.gov/timeseries/LNS14000000\"\n",
    "\n",
    "response=requests.get(national_unemp_url)\n",
    "doc=BeautifulSoup(response.text, 'html.parser')\n",
    "table=doc.find_all('table', {\"id\":\"table0\"})\n",
    "\n",
    "ele_list=[]\n",
    "\n",
    "for ele in table:\n",
    "    for ele1 in ele.find_all('tr'):  \n",
    "        for ele2 in ele1.find_all('td'):\n",
    "            ele_dict={}\n",
    "            ele_dict['year']=ele1.find('th').text.strip()\n",
    "            ele_dict['us_rate']=ele2.text.strip()\n",
    "            ele_list.append(ele_dict)            \n",
    "us_df=pd.DataFrame(ele_list)\n",
    "\n",
    "us_df=us_df[~(us_df.us_rate ==\"\")]\n",
    "us_df['us_rate']=us_df['us_rate'].astype(float)\n",
    "years=['2023','2022', '2021']\n",
    "us_df=us_df[us_df.year.isin(years)].reset_index(drop=True)\n",
    "us_df['month']=pd.Series(pd.period_range(\"1/1/2021\", freq=\"M\", periods=len(us_df))).astype(str)\n",
    "\n",
    "us_df=us_df[['month', 'us_rate']]\n",
    "\n",
    "# read nyc_rate and old data files\n",
    "nyc_rate =rate_df[['month', 'Unemp Rate']]\n",
    "final_us=pd.read_csv('raw_data/old_us_rate.csv')\n",
    "\n",
    "us_rate=pd.concat([us_df,final_us]).reset_index(drop=True).drop_duplicates()\n",
    "merged_rate=pd.merge(us_rate, nyc_rate)\n",
    "\n",
    "merged_rate['datetime']= pd.to_datetime(merged_rate.month)\n",
    "\n",
    "merged_rate=merged_rate.sort_values('datetime', ascending=False)[['month','us_rate','Unemp Rate'\n",
    "                                                                 ]].reset_index(drop=True)\n",
    "merged_rate.to_json('data/rate.json', orient='records')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22182f08",
   "metadata": {},
   "source": [
    "## Job Recovery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f49bb01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# direct download for NYC, no filtering needed\n",
    "jobsURL='statistics-total-nyc-nonfarm-jobs-seasonally-adjusted'\n",
    "\n",
    "r= requests.get(baseURL+jobsURL, allow_redirects=True)\n",
    "open('raw_data/raw_employment_data.xlsx', 'wb').write(r.content)\n",
    "# read the file\n",
    "jobs_df=pd.read_excel('raw_data/raw_employment_data.xlsx', skiprows=9)\n",
    "# # file out nan columns\n",
    "\n",
    "jobs_df=jobs_df[['YEAR', 'JAN', 'FEB', 'MAR', 'APR','MAY', 'JUN', 'JUL', 'AUG', 'SEP', 'OCT', 'NOV', 'DEC']]\n",
    "\n",
    "# create column names here\n",
    "column_names=['year', \"01\",\"02\",\"03\",\"04\",\"05\",\"06\",\"07\",\"08\",\"09\",\"10\",\"11\",\"12\"]\n",
    "# insert new columns names into the original dataset\n",
    "jobs_df.columns=column_names\n",
    "#filter data\n",
    "pandemic_years=[2020, 2021, 2022, 2023]\n",
    "jobs_df=jobs_df[jobs_df.year.isin(pandemic_years)].reset_index(drop=True)\n",
    "# flatten the data to. make it graphics ready\n",
    "jobs_df=jobs_df.melt(id_vars=['year'])\n",
    "# create a datetime column for viz purposes\n",
    "jobs_df['date']=pd.to_datetime(jobs_df.year.astype(str)+\"-\"+jobs_df.variable)\n",
    "jobs_df['month']=jobs_df.year.astype(str)+\"-\"+jobs_df.variable\n",
    "# replace  commas from the value column so that we can convert it into a string later\n",
    "jobs_df=jobs_df.replace(\",\", \"\", regex=True)\n",
    "# rename value column\n",
    "jobs_df=jobs_df[['date','month','value' ]].rename(columns={'value':'jobs'})\n",
    "# flter to get all entries after Jan 2020\n",
    "jobs_df=jobs_df[jobs_df.date > \"2020-01-31\"].reset_index(drop=True)\n",
    "# remove empty columns\n",
    "jobs_df['jobs']=jobs_df.jobs.replace(\" \", np.nan).astype(float)\n",
    "# drop na values\n",
    "jobs_df=jobs_df[jobs_df.jobs.notna()].reset_index(drop=True)\n",
    "# multiple by 1000 to create original value\n",
    "jobs_df['jobs']=(jobs_df.jobs*1000).astype(int)\n",
    "# sort columbs by datetime\n",
    "jobs_df=jobs_df.sort_values('date').reset_index(drop=True)\n",
    "#create a job loss column from baseline: Feb 2020\n",
    "jobs_df['jobloss_from_feb2020']=(jobs_df['jobs']-4715100.0).astype(int)\n",
    "jobs_df['jobs_added']=jobs_df.jobs.diff().fillna(0)\n",
    "#create two separate datasets\n",
    "jobs_added=jobs_df[['month','jobs_added']]\n",
    "job_recovery=jobs_df[['month','jobs','jobloss_from_feb2020']]\n",
    "#save files\n",
    "jobs_added.to_json('data/jobs_added.json', orient='records')\n",
    "job_recovery.to_json('data/job_recovery.json', orient='records')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a8dbba",
   "metadata": {},
   "source": [
    "## Earnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc007b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# direct download for NYC, no filtering needed\n",
    "earningsURL='statistics-state-and-area-employment-hours-and-earnings'\n",
    "\n",
    "r= requests.get(baseURL+earningsURL, allow_redirects=True)\n",
    "open('raw_data/earnings.xlsx', 'wb').write(r.content)\n",
    "# read the file\n",
    "\n",
    "earnings=pd.read_excel('raw_data/earnings.xlsx', sheet_name='average weekly earnings', skiprows=12)\n",
    "tp_earnings=earnings.set_index('Year').T[[\n",
    "    2007,2008,2009,2010,2011,2012,2013,2014,2015,2016,2017,2018,2019,2020, 2021,2022, 2023]]\n",
    "\n",
    "earnings=tp_earnings.T.reset_index().drop(columns='Annual')\n",
    "\n",
    "column_names=['year', \"01\",\"02\",\"03\",\"04\",\"05\",\"06\",\"07\",\"08\",\"09\",\"10\",\"11\",\"12\"]\n",
    "earnings.columns=column_names\n",
    "\n",
    "earning=earnings.replace(\",\", \"\", regex=True)\n",
    "earning=earnings.replace(\"$\", \"\", regex=True)\n",
    "\n",
    "earnings=earnings.melt(id_vars=['year']).dropna(subset=['value'])\n",
    "earnings=earnings.rename(columns={'value':'weekly_earnings'})\n",
    "earnings=earnings.sort_values(['year','variable']).reset_index(drop=True)\n",
    "\n",
    "earnings=earnings[earnings.year > 2010].reset_index(drop=True)\n",
    "earnings['month']=earnings.year.astype(str)+\"-\"+earnings.variable.astype(str)\n",
    "earnings['pct_chng_earnings']=(earnings.groupby('variable').weekly_earnings.pct_change()*100).round(1)\n",
    "\n",
    "earnings=earnings[earnings.pct_chng_earnings.notna()].reset_index(drop=True)\n",
    "\n",
    "earnings=earnings[['month', 'weekly_earnings', 'pct_chng_earnings']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c41d81",
   "metadata": {},
   "source": [
    "#### inflation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "42ba03bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "inflationURL=\"https://data.bls.gov/timeseries/CUURS12ASA0?output_view=pct_12mths&include_graphs=False\"\n",
    "\n",
    "response=requests.get(inflationURL)\n",
    "doc=BeautifulSoup(response.text, 'html.parser')\n",
    "table=doc.find_all('table', {\"id\":\"table0\"})\n",
    "\n",
    "tableList=[]\n",
    "columnList=[]\n",
    "for tr in table[0].find_all('tr'):\n",
    "    for col in tr.find_all('th', {'scope':'col'}):\n",
    "        columnDict={}\n",
    "        columnDict['category']= col.text.strip()    \n",
    "        columnList.append(columnDict)       \n",
    "    for row in tr.find_all('th', {'scope':'row'}): \n",
    "        for td in tr.find_all('td'):\n",
    "            tableDict={}\n",
    "            tableDict['year']=row.text.strip()\n",
    "            tableDict['value']=td.text.strip()\n",
    "            tableList.append(tableDict)\n",
    "table_df=pd.DataFrame(tableList)\n",
    "column_df=pd.DataFrame(columnList)\n",
    "\n",
    "pivoted=table_df.pivot(columns='year',values='value',index=None)\n",
    "\n",
    "dfList=[pivoted[[f'{column}']].dropna().reset_index(drop=True).T for column in pivoted.columns]\n",
    "inflation=pd.concat(dfList).reset_index()\n",
    "\n",
    "inflation=inflation.iloc[:, :13]\n",
    "column_names=['year', \"01\",\"02\",\"03\",\"04\",\"05\",\"06\",\"07\",\"08\",\"09\",\"10\",\"11\",\"12\"]\n",
    "inflation.columns=column_names\n",
    "inflation=inflation.melt(id_vars='year').rename(columns={'value':'yoy_chng_inf'})\n",
    "\n",
    "inflation=inflation[\n",
    "    inflation.yoy_chng_inf !=\"\"].reset_index(drop=True).sort_values(['year','variable']).reset_index(drop=True)\n",
    "inflation['month']=inflation.year.astype(str)+\"-\"+inflation.variable.astype(str)\n",
    "inflation=inflation[['month', 'yoy_chng_inf']]\n",
    "\n",
    "real_earnings=pd.merge(earnings, inflation)\n",
    "real_earnings.to_json('data/earnings.json', orient='records')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b332e533",
   "metadata": {},
   "source": [
    "## INDUSTRY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "05bfe298",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'Management, Scientific, and Technical Consulting Services'\n",
    "# https://www1.nyc.gov/assets/omb/downloads/csv/nycemploy-sa03-22.csv\n",
    "\n",
    "# significant_ind = [\n",
    "#    'Construction of Buildings','Couriers and messengers','Transportation and Warehousing',\n",
    "#     'Information', 'Financial Activities','Professional, Scientific, and Technical Services',\n",
    "#     'Administrative and Support Services','Educational Services','Ambulatory Health Care Services',\n",
    "#     'Social Assistance','Food Services and Drinking Places']\n",
    "    \n",
    "ombURL = 'https://www1.nyc.gov/assets/omb/js/pages/reports.js'\n",
    "response=requests.get(ombURL)\n",
    "doc=BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "df=pd.DataFrame(doc)\n",
    "trans=df[0].str.split(\"]\", expand=True).T\n",
    "trans=trans[trans[0].str.contains(\"Employment Data\")].reset_index(drop=True)\n",
    "trans[['indicator', 'release_date','no.', \"name\", \"URL\" ]]=trans[0].str.split(\",\", expand=True)\n",
    "trans=trans[[\"name\",'release_date',  \"URL\" ]]\n",
    "trans=trans.replace('\"', \"\", regex=True)\n",
    "trans['release_date']=trans.release_date.replace({\"4/21/203\":'4/21/2023'})\n",
    "trans['release_date']=pd.to_datetime(trans.release_date)\n",
    "trans=trans[~trans.name.str.contains(\"NSA\")]\n",
    "sorted_trans=trans.sort_values('release_date', ascending=False)\n",
    "sorted_trans\n",
    "# download excel file from the link in url\n",
    "url=sorted_trans.URL[0]\n",
    "baseURL='https://www1.nyc.gov'\n",
    "r= requests.get(baseURL+url, allow_redirects=True)\n",
    "\n",
    "open('raw_data/industry_data.csv', 'wb').write(r.content)\n",
    "# read the file\n",
    "ind_df=pd.read_csv('raw_data/industry_data.csv', skiprows=4)\n",
    "ind_df=ind_df[1:].reset_index(drop=True)\n",
    "\n",
    "\n",
    "new_df=(ind_df.set_index('Industry:').apply(pd.to_numeric)*1000).reset_index()\n",
    "new_df[['year', 'month']]=new_df['Industry:'].str.split('M', expand=True)\n",
    "filtered_df=new_df[new_df.year.astype(int) >= 2019].reset_index(drop=True)\n",
    "filtered_df['month']=filtered_df.year.astype(str)+\"-\"+filtered_df.month.astype(str)\n",
    "\n",
    "filtered_df=filtered_df[['month', 'Total Nonfarm', 'Total Private', 'Financial Activities','Finance and Insurance',\n",
    "     'Securities', 'Banking', 'Real Estate','Information', 'Professional and Business Services',\n",
    "     'Professional, Scientific, and Technical Services','Management of Companies and Enterprises', \n",
    "     'Administrative Services','Employment Services', 'Education and Health Services','Educational Services',\n",
    "    'Health Care and Social Assistance','Leisure and Hospitality', 'Arts, Entertainment, and Recreation',\n",
    "    ' Accommodation and Food Services', 'Other Services','Trade, Transportation, and Utilities', 'Retail Trade',\n",
    "    'Wholesale Trade', 'Transportation and Warehousing', 'Utilities','Construction', ' Manufacturing', ' Government']]\n",
    "\n",
    "filtered_df['datetime']=pd.to_datetime(filtered_df.month)\n",
    "filtered_df=filtered_df.sort_values('datetime', ascending=False)\n",
    "\n",
    "filtered_df=filtered_df.drop(columns='datetime')\n",
    "\n",
    "transposed=filtered_df.set_index('month').T.reset_index().rename(columns={\"index\":'sector'})\n",
    "\n",
    "transposed['sector']=transposed.sector.str.strip()\n",
    "\n",
    "transposed['yoy_chng']=(((transposed.iloc[:, 1]-transposed.iloc[:, 13])/transposed.iloc[:, 13])*100).round(1)\n",
    "transposed['2y_chng']=(((transposed.iloc[:, 1]-transposed.iloc[:, 25])/transposed.iloc[:, 25])*100).round(1)\n",
    "transposed['3y_chng']=(((transposed.iloc[:, 1]-transposed.iloc[:, 37])/transposed.iloc[:, 37])*100).round(1)\n",
    "\n",
    "# final_df=transposed[['sector','yoy_chng', '2y_chng', '3y_chng']]\n",
    "final_df=transposed.iloc[:,[0,1, -1, -2, -3]].sort_values('3y_chng', ascending=False).reset_index(drop=True)\n",
    "\n",
    "sectors=['Finance and Insurance', 'Real Estate','Information', 'Professional, Scientific, and Technical Services',\n",
    "         'Management of Companies and Enterprises', 'Administrative Services', 'Employment Services',\n",
    "         'Educational Services','Health Care and Social Assistance', 'Arts, Entertainment, and Recreation',\n",
    "         'Accommodation and Food Services', 'Retail Trade','Wholesale Trade', 'Transportation and Warehousing',\n",
    "         'Utilities','Construction', 'Manufacturing', 'Government']\n",
    "\n",
    "cleaned_df=final_df[final_df.sector.isin(sectors)].reset_index(drop=True)\n",
    "\n",
    "cleaned_df['month']=cleaned_df.columns[1]\n",
    "cleaned_df=cleaned_df.rename(columns={cleaned_df.columns[1]:'jobs'})\n",
    "\n",
    "cleaned_df.to_json('data/industry.json', orient='records')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43861565",
   "metadata": {},
   "source": [
    "# Office and Hotel Occupancy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5bf8f16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sheet_id = \"1JLlcLJ_dKBct7zK804L-p7P_7SYlIRegBHSfIKs8ek0\"\n",
    "sheet_name = \"office_occupancy\"\n",
    "officeURL = f'https://docs.google.com/spreadsheets/d/{sheet_id}/gviz/tq?tqx=out:csv&sheet={sheet_name}'\n",
    "\n",
    "oc=pd.read_csv(officeURL) \n",
    "oc=oc.replace(\"%\", \"\", regex=True)\n",
    "oc=oc.melt(id_vars='week_ending').rename(columns={'variable':'metro', 'value':'occupancy'})\n",
    "oc.to_json('data/occupancy.json', orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "38b44ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sheet_name = \"hotel_occupancy\"\n",
    "hotelURL = f'https://docs.google.com/spreadsheets/d/{sheet_id}/gviz/tq?tqx=out:csv&sheet={sheet_name}'\n",
    "\n",
    "hotel=pd.read_csv(hotelURL) \n",
    "demand=hotel[['period', 'demand2020', 'demand2021', 'demand2022']]\n",
    "change=hotel[['period', 'change2020', 'change2021', 'change2022']]\n",
    "\n",
    "demand.columns=demand.columns.str.replace('demand',\"\")\n",
    "change.columns=demand.columns.str.replace('change',\"\")\n",
    "\n",
    "melted_demand=demand.melt(id_vars='period').dropna().rename(\n",
    "    columns={'value':'demand', 'variable':'year'}).reset_index(drop=True)\n",
    "melted_change=change.melt(id_vars='period').dropna().rename(\n",
    "    columns={'value':'pct_chng', 'variable':'year'}).reset_index(drop=True)\n",
    "merged_hotel=pd.merge(melted_demand, melted_change, on=['period', 'year'])\n",
    "\n",
    "merged_hotel['month']=pd.to_datetime(merged_hotel.period+\"-\"+merged_hotel.year).dt.strftime(\"%Y-%m\")\n",
    "final_hotel=merged_hotel[['month', 'demand', 'pct_chng']].reset_index(drop=True)\n",
    "\n",
    "final_hotel.to_json('data/hotel_demand.json', orient='records')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a1d697a",
   "metadata": {},
   "source": [
    "# Subway ridership"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3b2ddd3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try: \n",
    "#     !wget -O raw_data/subway.csv \"https://data.ny.gov/api/views/vxuj-8kew/rows.csv?accessType=DOWNLOAD&sorting=true\"\n",
    "# except:\n",
    "#     pass\n",
    "#     print(\"No subway file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "67219f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "riders_df=pd.read_json(\"https://data.ny.gov/api/id/vxuj-8kew.json?$query=select%20*%2C%20%3Aid%20limit%2010000\")\n",
    "\n",
    "riders_df=riders_df[['date', 'subways_total_estimated_ridership', 'subways_of_comparable_pre_pandemic_day']]\n",
    "\n",
    "\n",
    "riders_df.columns=['date', 'riders', 'riders_recovered']\n",
    "\n",
    "riders_df['date']=pd.to_datetime(riders_df.date)\n",
    "\n",
    "riders_df=riders_df.sort_values(\"date\")\n",
    "\n",
    "riders_df['avg_recovery']=(riders_df.riders_recovered.rolling(window=7).mean()*100).round()\n",
    "riders_df['date']=pd.to_datetime(riders_df.date).dt.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "riders_df.to_json('data/subway_riders.json', orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5c3e9937",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c5c7745b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>riders</th>\n",
       "      <th>riders_recovered</th>\n",
       "      <th>avg_recovery</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1155</th>\n",
       "      <td>2020-03-01</td>\n",
       "      <td>2212965</td>\n",
       "      <td>0.97</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1154</th>\n",
       "      <td>2020-03-02</td>\n",
       "      <td>5329915</td>\n",
       "      <td>0.96</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1153</th>\n",
       "      <td>2020-03-03</td>\n",
       "      <td>5481103</td>\n",
       "      <td>0.98</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1152</th>\n",
       "      <td>2020-03-04</td>\n",
       "      <td>5498809</td>\n",
       "      <td>0.99</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1151</th>\n",
       "      <td>2020-03-05</td>\n",
       "      <td>5496453</td>\n",
       "      <td>0.99</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-04-26</td>\n",
       "      <td>3994458</td>\n",
       "      <td>0.72</td>\n",
       "      <td>71.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-04-27</td>\n",
       "      <td>3999197</td>\n",
       "      <td>0.72</td>\n",
       "      <td>71.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-04-28</td>\n",
       "      <td>3701849</td>\n",
       "      <td>0.66</td>\n",
       "      <td>72.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-04-29</td>\n",
       "      <td>2176648</td>\n",
       "      <td>0.69</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-04-30</td>\n",
       "      <td>1737895</td>\n",
       "      <td>0.71</td>\n",
       "      <td>69.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1156 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           date   riders  riders_recovered  avg_recovery\n",
       "1155 2020-03-01  2212965              0.97           NaN\n",
       "1154 2020-03-02  5329915              0.96           NaN\n",
       "1153 2020-03-03  5481103              0.98           NaN\n",
       "1152 2020-03-04  5498809              0.99           NaN\n",
       "1151 2020-03-05  5496453              0.99           NaN\n",
       "...         ...      ...               ...           ...\n",
       "4    2023-04-26  3994458              0.72          71.0\n",
       "3    2023-04-27  3999197              0.72          71.0\n",
       "2    2023-04-28  3701849              0.66          72.0\n",
       "1    2023-04-29  2176648              0.69          70.0\n",
       "0    2023-04-30  1737895              0.71          69.0\n",
       "\n",
       "[1156 rows x 4 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "riders_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d20c8d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
